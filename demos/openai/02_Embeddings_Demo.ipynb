{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "054425c2",
   "metadata": {},
   "source": [
    "# Azure OpenAI Embeddings デモ\n",
    "\n",
    "このNotebookでは Azure OpenAI Service の **Embeddings API** を用いてテキストを数値ベクトル（高次元特徴量）へ変換し、類似度計算・検索・分類・FAQマッチングなどの応用例を段階的に紹介します。\n",
    "\n",
    "### 🔰 Embeddings API 概要\n",
    "Embeddings はテキスト（単語 / 文 / 段落 / ドキュメント）を **意味的距離を反映した固定次元ベクトル** に変換します。これにより以下が可能になります:\n",
    "- 類似度検索（Semantic Search）\n",
    "- クラスタリング / 分類\n",
    "- レコメンデーション\n",
    "- RAG 前段のフィルタリング\n",
    "- FAQ マッチング / 重複検出\n",
    "\n",
    "### 🧬 利用可能な代表モデル（2025年時点 Azure OpenAI）\n",
    "| モデル | 次元数例 | 主用途 | 特徴 |\n",
    "|--------|----------|--------|------|\n",
    "| `text-embedding-3-large` | 3,072 | 高精度検索・分類 | 高次元・精度最重視 |\n",
    "| `text-embedding-3-small` | 1,536 | 一般用途/バランス | コスト/性能バランス良好 |\n",
    "| `text-embedding-ada-002` | 1,536 | 既存互換利用 | 旧世代。新規は3系推奨 |\n",
    "| `gpt-4o-mini-embeddings` | 1,536 | マルチ用途統合 | GPT-4o miniと連携設計 |\n",
    "\n",
    "> 新規開発は通常 **`text-embedding-3-small` → 精度要件が厳しければ `text-embedding-3-large`** の順で検討します。コスト最適化が重要な大量バッチ用途では small を推奨。\n",
    "\n",
    "### 🧪 このNotebookで扱う主な概念\n",
    "1. 基本的な埋め込み取得\n",
    "2. コサイン類似度計算\n",
    "3. Semantic Search の最小実装\n",
    "4. カテゴリ分類（ゼロショット的）\n",
    "5. FAQマッチング例\n",
    "6. バッチ埋め込み最適化\n",
    "7. 応用とベストプラクティス\n",
    "\n",
    "以降の各コードセル前に、実行する処理の概要を数行で説明します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7936da7",
   "metadata": {},
   "source": [
    "## 1. 環境セットアップ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52aef4c0",
   "metadata": {},
   "source": [
    "### 環境変数の設定\n",
    "\n",
    "リポジトリルートに `.env.dev` ファイルを作成し、以下の環境変数を設定してください：\n",
    "\n",
    "```bash\n",
    "# PowerShell の場合\n",
    "@\"\n",
    "AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/\n",
    "AZURE_OPENAI_API_KEY=your-api-key-here\n",
    "AZURE_OPENAI_API_VERSION=2024-08-01-preview\n",
    "EMBEDDING_DEPLOYMENT_NAME=text-embedding-ada-002\n",
    "\"@ | Out-File -FilePath ..\\..\\..env.dev -Encoding utf8\n",
    "```\n",
    "\n",
    "または、手動で `.env.dev` ファイルを作成してください。\n",
    "\n",
    "**注意**: `.env.dev` ファイルは `.gitignore` に含まれており、Git にコミットされません。\n",
    "\n",
    "---\n",
    "**補足1**: `.env.dev` の存在確認とテンプレート生成を行います。既にある場合は再生成せずユーザーに編集を促します。APIキー管理の初期準備ステップです。\n",
    "\n",
    "**補足2**: リポジトリルートの `.env.dev` を強制パースし、埋め込み API 呼び出しに必要なエンドポイントやキーを `os.environ` に設定します。空値は無視し、秘密情報は出力しません。\n",
    "\n",
    "**補足3**: Azure OpenAI クライアントを初期化し、使用する Embeddings モデル名を表示します。接続設定が正しく行われているか確認するフェーズです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ea9053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 必要なライブラリのインストール確認\n",
    "import sys\n",
    "print(f\"Python バージョン: {sys.version}\")\n",
    "\n",
    "try:\n",
    "    import openai\n",
    "    print(f\"✅ openai バージョン: {openai.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"❌ openai ライブラリがインストールされていません\")\n",
    "    print(\"インストール: pip install openai\")\n",
    "\n",
    "try:\n",
    "    import numpy\n",
    "    print(f\"✅ numpy バージョン: {numpy.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"❌ numpy ライブラリがインストールされていません\")\n",
    "    print(\"インストール: pip install numpy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97049728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .env.dev を強制パースして os.environ に直接設定する\n",
    "from dotenv import dotenv_values\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# ノートブックから見たリポジトリルートへの相対パス (demos/openai から ../../ でルートへ)\n",
    "repo_root = Path(__file__).parent.parent.parent if '__file__' in globals() else Path.cwd().parent.parent\n",
    "env_path = repo_root / '.env.dev'\n",
    "\n",
    "if env_path.exists():\n",
    "    # dotenv_values で .env.dev を辞書として読み込む\n",
    "    parsed = dotenv_values(env_path)\n",
    "    # 各キーを os.environ に書き込む(空文字や None はスキップ)\n",
    "    for k, v in parsed.items():\n",
    "        if v:\n",
    "            os.environ[k] = v\n",
    "    print(f'環境変数を読み込みました: {env_path}')\n",
    "    print(f'{len(parsed)} 個のキーをパースし、os.environ に設定しました。')\n",
    "else:\n",
    "    print(f'警告: {env_path} が見つかりません。')\n",
    "\n",
    "# 設定状況を確認\n",
    "print('\\n設定状況:')\n",
    "print('  AZURE_OPENAI_ENDPOINT:', 'SET' if os.getenv('AZURE_OPENAI_ENDPOINT') else 'NOT SET')\n",
    "print('  AZURE_OPENAI_API_KEY:', 'SET' if os.getenv('AZURE_OPENAI_API_KEY') else 'NOT SET')\n",
    "print('  EMBEDDING_DEPLOYMENT_NAME:', os.getenv('EMBEDDING_DEPLOYMENT_NAME', 'NOT SET'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37262ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Azure OpenAI クライアントの初期化\n",
    "from openai import AzureOpenAI\n",
    "import os\n",
    "\n",
    "# 環境変数から設定を取得\n",
    "endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\", \"2024-08-01-preview\")\n",
    "embedding_deployment = os.getenv(\"EMBEDDING_DEPLOYMENT_NAME\", \"text-embedding-ada-002\")\n",
    "\n",
    "# クライアントの初期化\n",
    "try:\n",
    "    client = AzureOpenAI(\n",
    "        api_key=api_key,\n",
    "        api_version=api_version,\n",
    "        azure_endpoint=endpoint\n",
    "    )\n",
    "    print(\"✅ Azure OpenAI クライアントが正常に初期化されました\")\n",
    "    print(f\"エンドポイント: {endpoint}\")\n",
    "    print(f\"API バージョン: {api_version}\")\n",
    "    print(f\"Embedding デプロイ名: {embedding_deployment}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ クライアントの初期化に失敗しました: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94574d94",
   "metadata": {},
   "source": [
    "## 2. 基本的な埋め込み生成\n",
    "\n",
    "**概要**: 単一テキストを埋め込みベクトルに変換する基本関数 `get_embedding` を定義します。戻り値は数値配列 (List[float]) で後続の類似度計算や検索、分類に利用します。埋め込みベクトルの次元数を確認し、先頭要素を抜粋表示して形状を把握します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d85c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text: str, model: str = None) -> list[float]:\n",
    "    \"\"\"\n",
    "    テキストの埋め込みベクトルを取得する\n",
    "    \n",
    "    Args:\n",
    "        text: 埋め込みを生成するテキスト\n",
    "        model: 使用するモデル名（デフォルトは環境変数から取得）\n",
    "        \n",
    "    Returns:\n",
    "        埋め込みベクトル（floatのリスト）\n",
    "    \"\"\"\n",
    "    if model is None:\n",
    "        model = embedding_deployment\n",
    "    \n",
    "    try:\n",
    "        response = client.embeddings.create(\n",
    "            input=text,\n",
    "            model=model\n",
    "        )\n",
    "        return response.data[0].embedding\n",
    "    except Exception as e:\n",
    "        print(f\"エラーが発生しました: {e}\")\n",
    "        return None\n",
    "\n",
    "# デモ実行\n",
    "sample_text = \"Azure AI Services は Microsoft が提供するクラウドベースの AI サービスです。\"\n",
    "embedding = get_embedding(sample_text)\n",
    "\n",
    "if embedding:\n",
    "    print(f\"テキスト: {sample_text}\")\n",
    "    print(f\"\\n埋め込みベクトルの次元数: {len(embedding)}\")\n",
    "    print(f\"最初の10要素: {embedding[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16dc5479",
   "metadata": {},
   "source": [
    "## 3. コサイン類似度の計算\n",
    "\n",
    "**概要**: 埋め込み同士の意味的近さを測るためにコサイン類似度関数 `cosine_similarity` を定義します。値域は -1〜1 で 1 に近いほど高い類似度です。複数テキスト間で比較し、近いペアと遠いペアのスコア差を確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e192400",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cosine_similarity(vec1: list[float], vec2: list[float]) -> float:\n",
    "    \"\"\"\n",
    "    2つのベクトル間のコサイン類似度を計算する\n",
    "    \n",
    "    Args:\n",
    "        vec1: ベクトル1\n",
    "        vec2: ベクトル2\n",
    "        \n",
    "    Returns:\n",
    "        コサイン類似度（-1 から 1 の範囲）\n",
    "    \"\"\"\n",
    "    vec1 = np.array(vec1)\n",
    "    vec2 = np.array(vec2)\n",
    "    \n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    norm1 = np.linalg.norm(vec1)\n",
    "    norm2 = np.linalg.norm(vec2)\n",
    "    \n",
    "    return dot_product / (norm1 * norm2)\n",
    "\n",
    "# 類似度計算のデモ\n",
    "text1 = \"犬は人間の最良の友です。\"\n",
    "text2 = \"犬は忠実なペットです。\"\n",
    "text3 = \"Python はプログラミング言語です。\"\n",
    "\n",
    "embedding1 = get_embedding(text1)\n",
    "embedding2 = get_embedding(text2)\n",
    "embedding3 = get_embedding(text3)\n",
    "\n",
    "if all([embedding1, embedding2, embedding3]):\n",
    "    similarity_1_2 = cosine_similarity(embedding1, embedding2)\n",
    "    similarity_1_3 = cosine_similarity(embedding1, embedding3)\n",
    "    similarity_2_3 = cosine_similarity(embedding2, embedding3)\n",
    "    \n",
    "    print(f\"テキスト1: {text1}\")\n",
    "    print(f\"テキスト2: {text2}\")\n",
    "    print(f\"テキスト3: {text3}\\n\")\n",
    "    \n",
    "    print(f\"類似度（テキスト1 vs テキスト2）: {similarity_1_2:.4f}\")\n",
    "    print(f\"類似度（テキスト1 vs テキスト3）: {similarity_1_3:.4f}\")\n",
    "    print(f\"類似度（テキスト2 vs テキスト3）: {similarity_2_3:.4f}\")\n",
    "    \n",
    "    print(\"\\n💡 解釈: 値が 1 に近いほど類似、0 に近いほど無関係\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b179ccde",
   "metadata": {},
   "source": [
    "## 4. セマンティック検索のデモ\n",
    "\n",
    "**概要**: コーパス（ドキュメント集合）の埋め込みを事前計算し、クエリ埋め込みとのコサイン類似度で上位候補を取得する最小実装 `semantic_search` を示します。スコアの高い順に並べることで意味的検索が成立します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61907dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# サンプルドキュメント（実際のアプリケーションではデータベースから取得）\n",
    "documents = [\n",
    "    \"Azure OpenAI Service は、OpenAI の強力な言語モデルを Azure で利用できるサービスです。\",\n",
    "    \"Azure Computer Vision は、画像から情報を抽出する AI サービスです。\",\n",
    "    \"Azure Speech Services は、音声認識と音声合成を提供します。\",\n",
    "    \"Azure Language Services は、テキスト分析や言語理解を可能にします。\",\n",
    "    \"Azure AI Services は、さまざまな AI 機能を提供する統合プラットフォームです。\",\n",
    "    \"機械学習モデルのトレーニングには大量のデータが必要です。\",\n",
    "    \"深層学習は、ニューラルネットワークを使用した機械学習の一種です。\",\n",
    "    \"自然言語処理（NLP）は、人間の言語をコンピュータが理解する技術です。\",\n",
    "]\n",
    "\n",
    "# 各ドキュメントの埋め込みを生成\n",
    "print(\"ドキュメントの埋め込みを生成中...\")\n",
    "doc_embeddings = []\n",
    "for i, doc in enumerate(documents):\n",
    "    embedding = get_embedding(doc)\n",
    "    if embedding:\n",
    "        doc_embeddings.append(embedding)\n",
    "        print(f\"✅ ドキュメント {i+1}/{len(documents)} 完了\")\n",
    "\n",
    "print(f\"\\n合計 {len(doc_embeddings)} 件のドキュメント埋め込みを生成しました\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3c6b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_search(query: str, documents: list[str], doc_embeddings: list[list[float]], top_k: int = 3) -> list[tuple[int, float, str]]:\n",
    "    \"\"\"\n",
    "    セマンティック検索を実行する\n",
    "    \n",
    "    Args:\n",
    "        query: 検索クエリ\n",
    "        documents: ドキュメントのリスト\n",
    "        doc_embeddings: ドキュメントの埋め込みベクトルのリスト\n",
    "        top_k: 返す結果の数\n",
    "        \n",
    "    Returns:\n",
    "        (インデックス, 類似度スコア, ドキュメント) のタプルのリスト\n",
    "    \"\"\"\n",
    "    # クエリの埋め込みを生成\n",
    "    query_embedding = get_embedding(query)\n",
    "    if not query_embedding:\n",
    "        return []\n",
    "    \n",
    "    # 各ドキュメントとの類似度を計算\n",
    "    similarities = []\n",
    "    for i, doc_emb in enumerate(doc_embeddings):\n",
    "        similarity = cosine_similarity(query_embedding, doc_emb)\n",
    "        similarities.append((i, similarity, documents[i]))\n",
    "    \n",
    "    # 類似度でソートして上位k件を返す\n",
    "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "    return similarities[:top_k]\n",
    "\n",
    "# セマンティック検索のデモ\n",
    "queries = [\n",
    "    \"テキストを理解する AI サービスは？\",\n",
    "    \"画像認識について教えてください\",\n",
    "    \"音声に関する技術は？\"\n",
    "]\n",
    "\n",
    "for query in queries:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"🔍 クエリ: {query}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    results = semantic_search(query, documents, doc_embeddings, top_k=3)\n",
    "    \n",
    "    for rank, (idx, score, doc) in enumerate(results, 1):\n",
    "        print(f\"\\n{rank}位 (類似度: {score:.4f})\")\n",
    "        print(f\"  {doc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcb9025",
   "metadata": {},
   "source": [
    "## 5. テキスト分類のデモ\n",
    "\n",
    "**概要**: カテゴリ代表文（説明）の埋め込みを辞書として保持し、入力文の埋め込みとの類似度で最も近いカテゴリを推定する簡易ゼロショット分類です。スコア閾値を導入すれば“不明”カテゴリを設けることも可能です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a9b96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# カテゴリとその説明\n",
    "categories = {\n",
    "    \"技術\": \"プログラミング、AI、機械学習、ソフトウェア開発に関するトピック\",\n",
    "    \"ビジネス\": \"経営、マーケティング、セールス、企業戦略に関するトピック\",\n",
    "    \"科学\": \"物理学、化学、生物学、自然科学に関するトピック\",\n",
    "    \"スポーツ\": \"サッカー、野球、オリンピック、フィットネスに関するトピック\",\n",
    "    \"料理\": \"レシピ、食材、調理法、グルメに関するトピック\"\n",
    "}\n",
    "\n",
    "# カテゴリ説明の埋め込みを生成\n",
    "print(\"カテゴリの埋め込みを生成中...\")\n",
    "category_embeddings = {}\n",
    "for category, description in categories.items():\n",
    "    embedding = get_embedding(description)\n",
    "    if embedding:\n",
    "        category_embeddings[category] = embedding\n",
    "        print(f\"✅ {category} 完了\")\n",
    "\n",
    "print(f\"\\n{len(category_embeddings)} 個のカテゴリ埋め込みを生成しました\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a7f91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_text(text: str, category_embeddings: dict[str, list[float]]) -> list[tuple[str, float]]:\n",
    "    \"\"\"\n",
    "    テキストを分類する\n",
    "    \n",
    "    Args:\n",
    "        text: 分類するテキスト\n",
    "        category_embeddings: カテゴリ名と埋め込みベクトルの辞書\n",
    "        \n",
    "    Returns:\n",
    "        (カテゴリ名, 類似度スコア) のタプルのリスト（スコア順）\n",
    "    \"\"\"\n",
    "    # テキストの埋め込みを生成\n",
    "    text_embedding = get_embedding(text)\n",
    "    if not text_embedding:\n",
    "        return []\n",
    "    \n",
    "    # 各カテゴリとの類似度を計算\n",
    "    scores = []\n",
    "    for category, cat_embedding in category_embeddings.items():\n",
    "        similarity = cosine_similarity(text_embedding, cat_embedding)\n",
    "        scores.append((category, similarity))\n",
    "    \n",
    "    # スコア順にソート\n",
    "    scores.sort(key=lambda x: x[1], reverse=True)\n",
    "    return scores\n",
    "\n",
    "# テキスト分類のデモ\n",
    "test_texts = [\n",
    "    \"Python で機械学習モデルを実装する方法について学んでいます。\",\n",
    "    \"今日の夕食にパスタを作りました。トマトソースが美味しかったです。\",\n",
    "    \"ワールドカップの決勝戦は素晴らしい試合でした。\",\n",
    "    \"新製品のマーケティング戦略を立案する必要があります。\",\n",
    "    \"量子力学の基礎原理について研究しています。\"\n",
    "]\n",
    "\n",
    "for text in test_texts:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"📝 テキスト: {text}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    results = classify_text(text, category_embeddings)\n",
    "    \n",
    "    print(\"\\n分類結果:\")\n",
    "    for rank, (category, score) in enumerate(results, 1):\n",
    "        bar_length = int(score * 50)  # スコアを棒グラフで表示\n",
    "        bar = '█' * bar_length + '░' * (50 - bar_length)\n",
    "        print(f\"{rank}. {category:10s} {score:.4f} {bar}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0919f6d2",
   "metadata": {},
   "source": [
    "## 6. バッチ処理（複数テキストの一括埋め込み）\n",
    "\n",
    "**概要**: 一度のAPI呼び出しで複数テキストを埋め込み取得する `get_embeddings_batch` により、ループ回数とネットワーク往復を削減しスループット・コストを最適化します。個別取得との次元・値の整合性を確認し、パフォーマンス改善の第一歩を示します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20781afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings_batch(texts: list[str], model: str = None) -> list[list[float]]:\n",
    "    \"\"\"\n",
    "    複数のテキストの埋め込みを一括取得する\n",
    "    \n",
    "    Args:\n",
    "        texts: テキストのリスト\n",
    "        model: 使用するモデル名\n",
    "        \n",
    "    Returns:\n",
    "        埋め込みベクトルのリスト\n",
    "    \"\"\"\n",
    "    if model is None:\n",
    "        model = embedding_deployment\n",
    "    \n",
    "    try:\n",
    "        response = client.embeddings.create(\n",
    "            input=texts,\n",
    "            model=model\n",
    "        )\n",
    "        return [item.embedding for item in response.data]\n",
    "    except Exception as e:\n",
    "        print(f\"エラーが発生しました: {e}\")\n",
    "        return []\n",
    "\n",
    "# バッチ処理のデモ\n",
    "batch_texts = [\n",
    "    \"Azure は Microsoft のクラウドプラットフォームです。\",\n",
    "    \"AI と機械学習はビジネスを変革しています。\",\n",
    "    \"クラウドコンピューティングは現代の IT インフラの基盤です。\"\n",
    "]\n",
    "\n",
    "print(\"バッチ処理で埋め込みを生成中...\")\n",
    "batch_embeddings = get_embeddings_batch(batch_texts)\n",
    "\n",
    "if batch_embeddings:\n",
    "    print(f\"\\n✅ {len(batch_embeddings)} 件の埋め込みを生成しました\")\n",
    "    for i, (text, embedding) in enumerate(zip(batch_texts, batch_embeddings), 1):\n",
    "        print(f\"\\n{i}. {text}\")\n",
    "        print(f\"   次元数: {len(embedding)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70bbb81",
   "metadata": {},
   "source": [
    "## 7. 実践的な使用例: FAQシステム\n",
    "\n",
    "**概要**: FAQエントリ質問文の埋め込みをインデックスし、ユーザー質問埋め込みとの類似度で最良候補を選択します。さらに閾値付き関数 `find_best_faq` で関連性が低い場合の fallback（未回答ハンドリング）を追加し、実サービス適用時の品質確保パターンを示します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc9af43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FAQ データベース\n",
    "faq_data = [\n",
    "    {\n",
    "        \"question\": \"Azure OpenAI Service とは何ですか？\",\n",
    "        \"answer\": \"Azure OpenAI Service は、OpenAI の強力な言語モデル（GPT-4、GPT-3.5、DALL-E など）を Azure のセキュリティとエンタープライズ機能と組み合わせたサービスです。\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"料金はどのように計算されますか？\",\n",
    "        \"answer\": \"Azure OpenAI Service の料金は、使用したトークン数に基づいて計算されます。モデルやリージョンによって価格が異なります。詳細は Azure の料金ページをご確認ください。\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"どのリージョンで利用できますか？\",\n",
    "        \"answer\": \"Azure OpenAI Service は、East US、West Europe、Japan East など、複数の Azure リージョンで利用可能です。最新の利用可能リージョンは公式ドキュメントをご確認ください。\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"API の呼び出し制限はありますか？\",\n",
    "        \"answer\": \"はい、レート制限があります。デプロイメントごとに TPM（Tokens Per Minute）と RPM（Requests Per Minute）の制限が設定されています。これらの制限は Azure Portal で調整可能です。\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"データのセキュリティは保証されていますか？\",\n",
    "        \"answer\": \"はい、Azure OpenAI Service は Azure のセキュリティ機能を継承しており、データの暗号化、プライベートエンドポイント、RBAC などのセキュリティ機能が利用できます。\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# FAQ の質問部分の埋め込みを生成\n",
    "print(\"FAQ データの埋め込みを生成中...\")\n",
    "faq_questions = [item[\"question\"] for item in faq_data]\n",
    "faq_embeddings = get_embeddings_batch(faq_questions)\n",
    "\n",
    "if faq_embeddings:\n",
    "    print(f\"✅ {len(faq_embeddings)} 件の FAQ 埋め込みを生成しました\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff72a1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_faq(user_question: str, faq_data: list[dict], faq_embeddings: list[list[float]], threshold: float = 0.7) -> tuple[dict, float] | None:\n",
    "    \"\"\"\n",
    "    ユーザーの質問に最も近い FAQ を検索する\n",
    "    \n",
    "    Args:\n",
    "        user_question: ユーザーの質問\n",
    "        faq_data: FAQ データのリスト\n",
    "        faq_embeddings: FAQ の埋め込みベクトルのリスト\n",
    "        threshold: 類似度の閾値（これ以上のスコアの場合のみ返す）\n",
    "        \n",
    "    Returns:\n",
    "        (FAQ アイテム, 類似度スコア) のタプル、または None\n",
    "    \"\"\"\n",
    "    # ユーザー質問の埋め込みを生成\n",
    "    question_embedding = get_embedding(user_question)\n",
    "    if not question_embedding:\n",
    "        return None\n",
    "    \n",
    "    # 最も類似度の高い FAQ を検索\n",
    "    best_score = -1\n",
    "    best_faq = None\n",
    "    \n",
    "    for faq_item, faq_emb in zip(faq_data, faq_embeddings):\n",
    "        similarity = cosine_similarity(question_embedding, faq_emb)\n",
    "        if similarity > best_score:\n",
    "            best_score = similarity\n",
    "            best_faq = faq_item\n",
    "    \n",
    "    # 閾値チェック\n",
    "    if best_score >= threshold:\n",
    "        return best_faq, best_score\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# FAQ システムのデモ\n",
    "user_questions = [\n",
    "    \"Azure OpenAI とは？\",\n",
    "    \"費用はいくらかかりますか？\",\n",
    "    \"日本で使えますか？\",\n",
    "    \"セキュリティは大丈夫？\",\n",
    "    \"天気はどうですか？\"  # 関連性の低い質問\n",
    "]\n",
    "\n",
    "for question in user_questions:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"❓ ユーザーの質問: {question}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    result = find_best_faq(question, faq_data, faq_embeddings, threshold=0.7)\n",
    "    \n",
    "    if result:\n",
    "        faq_item, score = result\n",
    "        print(f\"\\n✅ マッチした FAQ (類似度: {score:.4f}):\")\n",
    "        print(f\"Q: {faq_item['question']}\")\n",
    "        print(f\"\\nA: {faq_item['answer']}\")\n",
    "    else:\n",
    "        print(\"\\n❌ 関連する FAQ が見つかりませんでした。\")\n",
    "        print(\"カスタマーサポートにお問い合わせください。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb19026c",
   "metadata": {},
   "source": [
    "## まとめ\n",
    "\n",
    "このノートブックでは、Azure OpenAI の Embeddings API を使用して以下を実装しました：\n",
    "\n",
    "### 実装した機能\n",
    "1. ✅ テキストの埋め込みベクトル生成\n",
    "2. ✅ コサイン類似度の計算\n",
    "3. ✅ セマンティック検索\n",
    "4. ✅ テキスト分類\n",
    "5. ✅ バッチ処理\n",
    "6. ✅ FAQ システム（実践例）\n",
    "\n",
    "### 活用例\n",
    "- **検索システム**: キーワードマッチではなく意味的な検索\n",
    "- **推薦システム**: 類似コンテンツの推薦\n",
    "- **分類システム**: ドキュメントやメッセージの自動分類\n",
    "- **重複検出**: 類似テキストの検出\n",
    "- **クラスタリング**: テキストのグループ化\n",
    "\n",
    "### ベストプラクティス\n",
    "- バッチ処理を活用してコストと時間を削減\n",
    "- 埋め込みベクトルをキャッシュして再利用\n",
    "- 適切な閾値を設定して精度を向上\n",
    "- エラーハンドリングを実装\n",
    "\n",
    "### 次のステップ\n",
    "- ベクトルデータベース（Azure Cosmos DB, Azure Cognitive Search, Pinecone など）との統合\n",
    "- RAG（Retrieval-Augmented Generation）パターンの実装\n",
    "- より大規模なデータセットでの実験\n",
    "\n",
    "---\n",
    "**補足**: Cosmos DB などを活用する際はパーティションキー設計と埋め込みキャッシュ戦略（事前計算・更新頻度管理）を行い、ホットパーティション回避とクエリ効率化を図るとスケールが容易になります。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
