{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2dc66b2d",
   "metadata": {},
   "source": [
    "# Azure OpenAI GPT-4o ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³\n",
    "\n",
    "ã“ã®Notebookã§ã¯ã€Azure OpenAI Serviceã®GPT-4oãƒ¢ãƒ‡ãƒ«ã®åŸºæœ¬çš„ãªä½¿ç”¨æ–¹æ³•ã‚’ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã—ã¾ã™ã€‚\n",
    "\n",
    "## APIã®ç¨®é¡ã¨ä½¿ã„åˆ†ã‘\n",
    "\n",
    "ä¸»è¦ãªAPIã¨ã—ã¦ä»¥ä¸‹ã®3ã¤ãŒã‚ã‚Šã¾ã™ã€‚Assistants APIã¯ResponsesAPIã«çµ±åˆã•ã‚Œã€2026/08 ã« Deprecate ã•ã‚Œã‚‹ã“ã¨ãŒç™ºè¡¨ã•ã‚Œã¦ã„ã¾ã™ã®ã§ã€å®Ÿè³ª  Chat Completions API ã¨ Responses API ã®2æŠã«ãªã‚Šã¾ã™ã€‚\n",
    "\n",
    "### Chat Completions API\n",
    "- åºƒãä½¿ã‚ã‚Œã¦ã„ã‚‹â€œæ¨™æº–â€ã®ä¼šè©±ç”Ÿæˆã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ã‚¤ã‚¹ã€‚\n",
    "- å…¥åŠ›ã¯messagesã®é…åˆ—ï¼ˆsystem/developer/userãªã©ï¼‰ã§ã€å‘¼ã³å‡ºã—ã¯åŸºæœ¬çš„ã«ã‚¹ãƒ†ãƒ¼ãƒˆãƒ¬ã‚¹ã€‚\n",
    "- ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ã¯å¯èƒ½ã ãŒã€ä¼šè©±å±¥æ­´ã‚„ãƒ„ãƒ¼ãƒ«ã®å‡ºåŠ›é€£æºã¯ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå´ã§ç®¡ç†ã™ã‚‹å‰æã€‚\n",
    "\n",
    "### Responses API\n",
    "- 2025/03 ã«ç™»å ´ã—ãŸæ¬¡ä¸–ä»£ãƒ»çµ±åˆã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ã‚¤ã‚¹\n",
    "- Chat Completions ã®ç°¡æ½”ã•ã‚’ä¿ã¡ã¤ã¤ã€ãƒ„ãƒ¼ãƒ«åˆ©ç”¨ï¼ˆweb/file/computer use ãªã©ï¼‰ã‚„ã‚µãƒ¼ãƒå´ã®çŠ¶æ…‹ç®¡ç†ï¼ˆstore:true/previous_response_idï¼‰ã‚’å˜ä¸€ãƒªã‚¯ã‚¨ã‚¹ãƒˆã§æ‰±ãˆã‚‹\n",
    "- ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆçš„ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ï¼ˆmultiâ€‘turnï¼‹è¤‡æ•°ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ï¼‰ã«æœ€é©\n",
    "- Azure AI Foundry ã§ã¯ GAï¼ˆä¸€èˆ¬æä¾›ï¼‰\n",
    "\n",
    "### ï¼ˆdeprecateäºˆå®šï¼‰Assistants API\n",
    "- 2023ã€œ2024ã«æä¾›é–‹å§‹ã•ã‚ŒãŸçŠ¶æ…‹ç®¡ç†ä»˜ãã®â€œã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆâ€æ§‹ç¯‰ APIï¼ˆAssistant/Thread/Runãªã©ã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã§ä¼šè©±ã‚’ä¿æŒï¼‰\n",
    "- Responses API ã¸ã®ç½®ãæ›ãˆæ–¹é‡ãŒå…¬å¼ã«ç¤ºã•ã‚Œã¦ãŠã‚Šã€2026å¹´ä¸­é ƒã«ã‚µãƒ³ã‚»ãƒƒãƒˆäºˆå®šï¼ˆæ®µéšçš„ã«ç¸®é€€ï¼‰\n",
    "- ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚µãƒ¼ãƒ“ã‚¹ï¼ˆAzure AI Foundry Agent Serviceï¼‰ã¯ã“ã®ç³»è­œã®æ¦‚å¿µãƒ»ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã‚’è¸è¥²\n",
    "\n",
    "ã“ã“ã§ã¯ã€åŸºæœ¬çš„ãªãƒ‡ãƒ¢ã¨ã—ã¦ `Chat Completions API` ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚\n",
    "\n",
    "\n",
    "## å‰ææ¡ä»¶\n",
    "\n",
    "1. Azure OpenAI Serviceãƒªã‚½ãƒ¼ã‚¹ãŒãƒ‡ãƒ—ãƒ­ã‚¤ã•ã‚Œã¦ã„ã‚‹\n",
    "2. GPT-4oãƒ¢ãƒ‡ãƒ«ãŒãƒ‡ãƒ—ãƒ­ã‚¤ã•ã‚Œã¦ã„ã‚‹\n",
    "3. å¿…è¦ãªPythonãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹\n",
    "4. ç’°å¢ƒå¤‰æ•°ãŒé©åˆ‡ã«è¨­å®šã•ã‚Œã¦ã„ã‚‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9a439c",
   "metadata": {},
   "source": [
    "## 1. ç’°å¢ƒè¨­å®šã¨å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcfb8b1",
   "metadata": {},
   "source": [
    "### ç’°å¢ƒå¤‰æ•°ã®è¨­å®š\n",
    "\n",
    "ã“ã“ã§ã¯ã€å¿…è¦ãªç’°å¢ƒå¤‰æ•°ã‚’.envã‹ã‚‰èª­ã¿å‡ºã™æ–¹å¼ã§ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¨­å®šã—ã¾ã™ã€‚ï¼ˆãƒ†ã‚¹ãƒˆç”¨ã®ç°¡æ˜“æ–¹å¼ã§ã™ã€‚ï¼‰\n",
    "Notebook ã¨åŒã˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã« `.env` ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã€æ¬¡ã®å†…å®¹ã‚’ä¿å­˜ã—ã¾ã™ã€‚\n",
    "```ini\n",
    "AZURE_OPENAI_ENDPOINT=https://<your-resource>.openai.azure.com/\n",
    "AZURE_OPENAI_API_KEY=<your-api-key>\n",
    "AZURE_OPENAI_API_VERSION=2024-02-15-preview\n",
    "GPT4O_DEPLOYMENT_NAME=gpt-4o\n",
    "```\n",
    "\n",
    "æ³¨æ„: API ã‚­ãƒ¼ç­‰ã®æ©Ÿå¯†æƒ…å ±ã¯ãƒªãƒã‚¸ãƒˆãƒªã«ã‚³ãƒŸãƒƒãƒˆã—ãªã„ã§ãã ã•ã„ã€‚æ—¢ã«ã‚³ãƒŸãƒƒãƒˆã—ã¦ã—ã¾ã£ãŸå ´åˆã¯ã€é€Ÿã‚„ã‹ã«ã‚­ãƒ¼ã‚’ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã—ã€å±¥æ­´ã‹ã‚‰ã®é™¤å»æ‰‹é †ã‚’å®Ÿæ–½ã—ã¦ãã ã•ã„ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16b3b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .env ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ä½œæˆã™ã‚‹ï¼ˆå­˜åœ¨ã—ãªã„å ´åˆã®ã¿ï¼‰\n",
    "from pathlib import Path\n",
    "env_path = Path('.env')\n",
    "if not env_path.exists():\n",
    "    env_path.write_text('AZURE_OPENAI_ENDPOINT=\\nAZURE_OPENAI_API_KEY=\\nAZURE_OPENAI_API_VERSION=2024-02-15-preview\\nGPT4O_DEPLOYMENT_NAME=gpt-4o\\n')\n",
    "    print('.env ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ä½œæˆã—ã¾ã—ãŸã€‚å€¤ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚')\n",
    "else:\n",
    "    print('.env ã¯æ—¢ã«å­˜åœ¨ã—ã¾ã™ã€‚ç·¨é›†ã—ã¦ãã ã•ã„ã€‚')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42bafb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\n",
    "import sys\n",
    "!{sys.executable} -m pip install openai python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873929b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .env.dev ã‚’å¼·åˆ¶ãƒ‘ãƒ¼ã‚¹ã—ã¦ os.environ ã«ç›´æ¥è¨­å®šã™ã‚‹\n",
    "from dotenv import dotenv_values\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã‹ã‚‰è¦‹ãŸãƒªãƒã‚¸ãƒˆãƒªãƒ«ãƒ¼ãƒˆã¸ã®ç›¸å¯¾ãƒ‘ã‚¹ (demos/openai ã‹ã‚‰ ../../ ã§ãƒ«ãƒ¼ãƒˆã¸)\n",
    "repo_root = Path(__file__).parent.parent.parent if '__file__' in globals() else Path.cwd().parent.parent\n",
    "env_path = repo_root / '.env.dev'\n",
    "\n",
    "if env_path.exists():\n",
    "    # dotenv_values ã§ .env.dev ã‚’è¾æ›¸ã¨ã—ã¦èª­ã¿è¾¼ã‚€\n",
    "    parsed = dotenv_values(env_path)\n",
    "    # å„ã‚­ãƒ¼ã‚’ os.environ ã«æ›¸ãè¾¼ã‚€(ç©ºæ–‡å­—ã‚„ None ã¯ã‚¹ã‚­ãƒƒãƒ—)\n",
    "    for k, v in parsed.items():\n",
    "        if v:\n",
    "            os.environ[k] = v\n",
    "    print(f'ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: {env_path}')\n",
    "    print(f'{len(parsed)} å€‹ã®ã‚­ãƒ¼ã‚’ãƒ‘ãƒ¼ã‚¹ã—ã€os.environ ã«è¨­å®šã—ã¾ã—ãŸã€‚')\n",
    "else:\n",
    "    print(f'è­¦å‘Š: {env_path} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚')\n",
    "\n",
    "# è¨­å®šçŠ¶æ³ã‚’ç¢ºèª\n",
    "print('è¨­å®šçŠ¶æ³:')\n",
    "print('  AZURE_OPENAI_ENDPOINT:', 'SET' if os.getenv('AZURE_OPENAI_ENDPOINT') else 'NOT SET')\n",
    "print('  AZURE_OPENAI_API_KEY:', 'SET' if os.getenv('AZURE_OPENAI_API_KEY') else 'NOT SET')\n",
    "print('  GPT4O_DEPLOYMENT_NAME:', os.getenv('GPT4O_DEPLOYMENT_NAME'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e6aafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿\n",
    "load_dotenv()\n",
    "\n",
    "# è¨­å®šã®ç¢ºèª\n",
    "print(\"=== Azure OpenAI è¨­å®šç¢ºèª ===\")\n",
    "endpoint = os.getenv('AZURE_OPENAI_ENDPOINT')\n",
    "api_version = os.getenv('AZURE_OPENAI_API_VERSION', '2024-02-15-preview')\n",
    "deployment_name = os.getenv('GPT4O_DEPLOYMENT_NAME', 'gpt-4o')\n",
    "\n",
    "print(f\"ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ: {endpoint}\")\n",
    "print(f\"APIãƒãƒ¼ã‚¸ãƒ§ãƒ³: {api_version}\")\n",
    "print(f\"ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆå: {deployment_name}\")\n",
    "\n",
    "if not endpoint:\n",
    "    print(\"âš ï¸ AZURE_OPENAI_ENDPOINT ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“\")\n",
    "else:\n",
    "    print(\"âœ… è¨­å®šãŒç¢ºèªã•ã‚Œã¾ã—ãŸ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c676bc8",
   "metadata": {},
   "source": [
    "## 2. Azure OpenAI ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a22313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Azure OpenAI ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–\n",
    "try:\n",
    "    client = openai.AzureOpenAI(\n",
    "        azure_endpoint=endpoint,\n",
    "        api_key=os.getenv('AZURE_OPENAI_API_KEY'),\n",
    "        api_version=api_version\n",
    "    )\n",
    "    print(\"âœ… Azure OpenAI ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒæ­£å¸¸ã«åˆæœŸåŒ–ã•ã‚Œã¾ã—ãŸ\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {str(e)}\")\n",
    "    print(\"APIã‚­ãƒ¼ãŒæ­£ã—ãè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859de760",
   "metadata": {},
   "source": [
    "## 3. åŸºæœ¬çš„ãªãƒãƒ£ãƒƒãƒˆæ©Ÿèƒ½ã®ãƒ‡ãƒ¢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c05605a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_with_gpt4o(message, system_message=\"ã‚ãªãŸã¯è¦ªåˆ‡ãªAIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚\"):\n",
    "    \"\"\"\n",
    "    GPT-4oã¨ã®åŸºæœ¬çš„ãªãƒãƒ£ãƒƒãƒˆæ©Ÿèƒ½\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=deployment_name,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_message},\n",
    "                {\"role\": \"user\", \"content\": message}\n",
    "            ],\n",
    "            max_tokens=800,\n",
    "            temperature=0.7\n",
    "        )\n",
    "        \n",
    "        return response.choices[0].message.content\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}\"\n",
    "\n",
    "# ãƒ‡ãƒ¢å®Ÿè¡Œ\n",
    "test_message = \"Azure AI Servicesã«ã¤ã„ã¦ç°¡æ½”ã«èª¬æ˜ã—ã¦ãã ã•ã„ã€‚\"\n",
    "print(f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼: {test_message}\")\n",
    "print(f\"\\nGPT-4o: {chat_with_gpt4o(test_message)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595729c0",
   "metadata": {},
   "source": [
    "## 4. ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¿œç­”ã®ãƒ‡ãƒ¢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675d793b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_chat_with_gpt4o(message, system_message=\"ã‚ãªãŸã¯è¦ªåˆ‡ãªAIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚\"):\n",
    "    \"\"\"\n",
    "    ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å½¢å¼ã§ã®GPT-4oå¿œç­”\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=deployment_name,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_message},\n",
    "                {\"role\": \"user\", \"content\": message}\n",
    "            ],\n",
    "            max_tokens=800,\n",
    "            temperature=0.7,\n",
    "            stream=True\n",
    "        )\n",
    "        \n",
    "        print(\"GPT-4o (ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°): \", end=\"\", flush=True)\n",
    "        full_response = \"\"\n",
    "        \n",
    "        for chunk in response:\n",
    "            # choices ãŒå­˜åœ¨ã—ã€delta ã« content ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯\n",
    "            if chunk.choices and len(chunk.choices) > 0:\n",
    "                delta = chunk.choices[0].delta\n",
    "                if hasattr(delta, 'content') and delta.content is not None:\n",
    "                    content = delta.content\n",
    "                    print(content, end=\"\", flush=True)\n",
    "                    full_response += content\n",
    "        \n",
    "        print(\"\\n\")\n",
    "        return full_response\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ‡ãƒ¢å®Ÿè¡Œ\n",
    "stream_message = \"Azure Cognitive Servicesã®ä¸»è¦ãªæ©Ÿèƒ½ã‚’3ã¤æ•™ãˆã¦ãã ã•ã„ã€‚\"\n",
    "print(f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼: {stream_message}\\n\")\n",
    "stream_response = stream_chat_with_gpt4o(stream_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d73d0a",
   "metadata": {},
   "source": [
    "## 5. ç•°ãªã‚‹æ¸©åº¦è¨­å®šã§ã®å¿œç­”æ¯”è¼ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9a0e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_temperature_responses(message, temperatures=[0.0, 0.5, 1.0]):\n",
    "    \"\"\"\n",
    "    ç•°ãªã‚‹æ¸©åº¦è¨­å®šã§ã®å¿œç­”ã‚’æ¯”è¼ƒ\n",
    "    \"\"\"\n",
    "    print(f\"è³ªå•: {message}\\n\")\n",
    "    \n",
    "    for temp in temperatures:\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=deployment_name,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"ã‚ãªãŸã¯ç°¡æ½”ã«ç­”ãˆã‚‹AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚\"},\n",
    "                    {\"role\": \"user\", \"content\": message}\n",
    "                ],\n",
    "                max_tokens=200,\n",
    "                temperature=temp\n",
    "            )\n",
    "            \n",
    "            print(f\"ğŸŒ¡ï¸ æ¸©åº¦è¨­å®š {temp}:\")\n",
    "            print(f\"{response.choices[0].message.content}\\n\")\n",
    "            print(\"-\" * 50)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"æ¸©åº¦ {temp} ã§ã‚¨ãƒ©ãƒ¼: {str(e)}\\n\")\n",
    "\n",
    "# æ¸©åº¦æ¯”è¼ƒãƒ‡ãƒ¢\n",
    "comparison_question = \"ã‚¯ãƒ©ã‚¦ãƒ‰ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã®åˆ©ç‚¹ã‚’1ã¤æ•™ãˆã¦ãã ã•ã„ã€‚\"\n",
    "compare_temperature_responses(comparison_question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0870af",
   "metadata": {},
   "source": [
    "## 6. ä½¿ç”¨é‡ã¨ã‚³ã‚¹ãƒˆã®ç›£è¦–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ac9a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_usage_info(response):\n",
    "    \"\"\"\n",
    "    APIå¿œç­”ã‹ã‚‰ä½¿ç”¨é‡æƒ…å ±ã‚’å–å¾—\n",
    "    \"\"\"\n",
    "    if hasattr(response, 'usage'):\n",
    "        usage = response.usage\n",
    "        print(\"ğŸ“Š ä½¿ç”¨é‡æƒ…å ±:\")\n",
    "        print(f\"  - ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒˆãƒ¼ã‚¯ãƒ³: {usage.prompt_tokens}\")\n",
    "        print(f\"  - å®Œäº†ãƒˆãƒ¼ã‚¯ãƒ³: {usage.completion_tokens}\")\n",
    "        print(f\"  - ç·ãƒˆãƒ¼ã‚¯ãƒ³: {usage.total_tokens}\")\n",
    "        return usage\n",
    "    return None\n",
    "\n",
    "# ä½¿ç”¨é‡ç›£è¦–ä»˜ãã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆä¾‹\n",
    "try:\n",
    "    usage_response = client.chat.completions.create(\n",
    "        model=deployment_name,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"ã‚ãªãŸã¯æŠ€è¡“çš„ãªAIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚\"},\n",
    "            {\"role\": \"user\", \"content\": \"æ©Ÿæ¢°å­¦ç¿’ã¨æ·±å±¤å­¦ç¿’ã®é•ã„ã‚’æ•™ãˆã¦ãã ã•ã„ã€‚\"}\n",
    "        ],\n",
    "        max_tokens=300,\n",
    "        temperature=0.7\n",
    "    )\n",
    "    \n",
    "    print(\"å›ç­”:\")\n",
    "    print(usage_response.choices[0].message.content)\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    get_usage_info(usage_response)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"ã‚¨ãƒ©ãƒ¼: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceee23ff",
   "metadata": {},
   "source": [
    "## 7. å¯¾è©±å±¥æ­´ã‚’ä¿æŒã™ã‚‹ãƒãƒ£ãƒƒãƒˆã‚»ãƒƒã‚·ãƒ§ãƒ³"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af564350",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatSession:\n",
    "    def __init__(self, system_message=\"ã‚ãªãŸã¯è¦ªåˆ‡ã§çŸ¥è­˜è±Šå¯ŒãªAIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚\"):\n",
    "        self.messages = [{\"role\": \"system\", \"content\": system_message}]\n",
    "        self.total_tokens_used = 0\n",
    "    \n",
    "    def send_message(self, user_message):\n",
    "        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å±¥æ­´ã«è¿½åŠ \n",
    "        self.messages.append({\"role\": \"user\", \"content\": user_message})\n",
    "        \n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=deployment_name,\n",
    "                messages=self.messages,\n",
    "                max_tokens=500,\n",
    "                temperature=0.7\n",
    "            )\n",
    "            \n",
    "            assistant_message = response.choices[0].message.content\n",
    "            \n",
    "            # ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã®å¿œç­”ã‚’å±¥æ­´ã«è¿½åŠ \n",
    "            self.messages.append({\"role\": \"assistant\", \"content\": assistant_message})\n",
    "            \n",
    "            # ä½¿ç”¨é‡ã‚’è¿½è·¡\n",
    "            if hasattr(response, 'usage'):\n",
    "                self.total_tokens_used += response.usage.total_tokens\n",
    "            \n",
    "            return assistant_message\n",
    "        \n",
    "        except Exception as e:\n",
    "            return f\"ã‚¨ãƒ©ãƒ¼: {str(e)}\"\n",
    "    \n",
    "    def get_conversation_history(self):\n",
    "        return [msg for msg in self.messages if msg[\"role\"] != \"system\"]\n",
    "    \n",
    "    def clear_history(self):\n",
    "        # ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ä»¥å¤–ã‚’ã‚¯ãƒªã‚¢\n",
    "        self.messages = [self.messages[0]]\n",
    "        self.total_tokens_used = 0\n",
    "\n",
    "# ãƒãƒ£ãƒƒãƒˆã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ãƒ‡ãƒ¢\n",
    "chat = ChatSession(\"ã‚ãªãŸã¯Azureå°‚é–€ã®ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒ¼ã§ã™ã€‚\")\n",
    "\n",
    "# è¤‡æ•°ã®ã‚„ã‚Šå–ã‚Šã‚’ãƒ‡ãƒ¢\n",
    "questions = [\n",
    "    \"Azure OpenAIã¨ã¯ä½•ã§ã™ã‹ï¼Ÿ\",\n",
    "    \"å…ˆã»ã©ã®å›ç­”ã§è¨€åŠã•ã‚ŒãŸGPT-4ã«ã¤ã„ã¦è©³ã—ãæ•™ãˆã¦ãã ã•ã„ã€‚\",\n",
    "    \"ã‚³ã‚¹ãƒˆæœ€é©åŒ–ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿ\"\n",
    "]\n",
    "\n",
    "for i, question in enumerate(questions, 1):\n",
    "    print(f\"\\nğŸ’¬ ä¼šè©± {i}:\")\n",
    "    print(f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼: {question}\")\n",
    "    answer = chat.send_message(question)\n",
    "    print(f\"ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ: {answer}\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "print(f\"\\nğŸ“Š ã‚»ãƒƒã‚·ãƒ§ãƒ³ç·è¨ˆ: {chat.total_tokens_used} ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8333cf",
   "metadata": {},
   "source": [
    "## 8. ã¾ã¨ã‚\n",
    "\n",
    "ã“ã®Notebookã§ã¯ä»¥ä¸‹ã®æ©Ÿèƒ½ã‚’ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã—ã¾ã—ãŸ:\n",
    "\n",
    "1. âœ… **ç’°å¢ƒè¨­å®š**: Azure OpenAI ã®æ¥ç¶šè¨­å®š\n",
    "2. âœ… **åŸºæœ¬ãƒãƒ£ãƒƒãƒˆ**: å˜ç™ºã®è³ªå•å¿œç­”\n",
    "3. âœ… **ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¿œç­”**: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§ã®å¿œç­”è¡¨ç¤º\n",
    "4. âœ… **ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´**: æ¸©åº¦è¨­å®šã«ã‚ˆã‚‹å¿œç­”ã®é•ã„\n",
    "5. âœ… **ä½¿ç”¨é‡ç›£è¦–**: ãƒˆãƒ¼ã‚¯ãƒ³æ¶ˆè²»é‡ã®è¿½è·¡\n",
    "6. âœ… **å¯¾è©±ã‚»ãƒƒã‚·ãƒ§ãƒ³**: ä¼šè©±å±¥æ­´ã‚’ä¿æŒã—ãŸãƒãƒ£ãƒƒãƒˆ\n",
    "\n",
    "### æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—\n",
    "\n",
    "- ä»–ã®Azure AI Servicesã¨ã®é€£æº\n",
    "- ã‚ˆã‚Šé«˜åº¦ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°\n",
    "- é–¢æ•°å‘¼ã³å‡ºã—ï¼ˆFunction Callingï¼‰ã®å®Ÿè£…\n",
    "- RAGï¼ˆRetrieval-Augmented Generationï¼‰ãƒ‘ã‚¿ãƒ¼ãƒ³ã®å®Ÿè£…\n",
    "\n",
    "### å‚è€ƒãƒªãƒ³ã‚¯\n",
    "\n",
    "- [Azure OpenAI Service ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ](https://docs.microsoft.com/azure/cognitive-services/openai/)\n",
    "- [OpenAI Python ãƒ©ã‚¤ãƒ–ãƒ©ãƒª](https://github.com/openai/openai-python)\n",
    "- [Azure AI Services](https://docs.microsoft.com/azure/cognitive-services/)\n",
    "- [OpenAI å…¬å¼ï¼ˆResponses ç§»è¡Œã‚¬ã‚¤ãƒ‰ï¼‰](https://platform.openai.com/docs/guides/migrate-to-responses)\n",
    "- [Azure Learnï¼ˆResponses API æ¦‚è¦ãƒ»ãƒªãƒ¼ã‚¸ãƒ§ãƒ³ãƒ»ãƒ¢ãƒ‡ãƒ«ãƒ»æ—¢çŸ¥åˆ¶é™ï¼‰](https://learn.microsoft.com/en-us/azure/ai-foundry/openai/how-to/responses)\n",
    "- [Responses API is now generally available](https://azurefeeds.com/2025/08/28/the-responses-api-in-azure-ai-foundry-is-now-generally-available/)\n",
    "- [Assistants API ã®ãƒ‡ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³](https://platform.openai.com/docs/deprecations/deprecations)\n",
    "- [OpenAI API: Responses vs Chat Completions](https://simonwillison.net/2025/Mar/11/responses-vs-chat-completions/) \n",
    "- [Azure AI Foundry Blog: New tools in Responses](https://devblogs.microsoft.com/foundry/introducing-new-tools-and-features-in-the-responses-api-in-azure-ai-foundry/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
